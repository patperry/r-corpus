<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to corpus • corpus</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-4636081-3', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">corpus</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/corpus.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/chinese.html">Chinese text handling</a>
    </li>
    <li>
      <a href="../articles/gender.html">Finding gendered words</a>
    </li>
    <li>
      <a href="../articles/textdata.html">Text data in Corpus and other packages</a>
    </li>
    <li>
      <a href="../articles/unicode.html">Unicode: Emoji, accents, and international text</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Introduction to corpus</h1>
            
          </div>

    
    
<div class="contents">
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>This vignette demonstrates the functionality provided by the <em>corpus</em> R package. The running example throughout is an analysis of the text of L. Frank Baum’s novel, <em>The Wonderful Wizard of Oz</em>.</p>
</div>
<div id="setup" class="section level2">
<h2 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h2>
<p>We load the <em>corpus</em> package, set the color palette, and set the random number generator seed. We will not use any external packages in this vignette.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"corpus"</span>)

<span class="co"># colors from RColorBrewer::brewer.pal(6, "Set1")</span>
<span class="kw">palette</span>(<span class="kw">c</span>(<span class="st">"#E41A1C"</span>, <span class="st">"#377EB8"</span>, <span class="st">"#4DAF4A"</span>, <span class="st">"#984EA3"</span>, <span class="st">"#FF7F00"</span>, <span class="st">"#FFFF33"</span>))

<span class="co"># ensure consistent runs</span>
<span class="kw">set.seed</span>(<span class="dv">0</span>)</code></pre></div>
</div>
<div id="data-preparation" class="section level2">
<h2 class="hasAnchor">
<a href="#data-preparation" class="anchor"></a>Data preparation</h2>
<p>The <em>The Wonderful Wizard of Oz</em> is available as <a href="http://www.gutenberg.org/ebooks/55" title="The Wonderful Wizard of Oz">Project Gutenberg EBook #55</a>. We first download the text and strip off the Project Gutenberg header and footer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">url &lt;-<span class="st"> "http://www.gutenberg.org/cache/epub/55/pg55.txt"</span>
raw &lt;-<span class="st"> </span><span class="kw">readLines</span>(url, <span class="dt">encoding =</span> <span class="st">"UTF-8"</span>)

<span class="co"># the text starts after the Project Gutenberg header...</span>
start &lt;-<span class="st"> </span><span class="kw">grep</span>(<span class="st">"^</span><span class="ch">\\</span><span class="st">*</span><span class="ch">\\</span><span class="st">*</span><span class="ch">\\</span><span class="st">* START OF THIS PROJECT GUTENBERG EBOOK"</span>, raw) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>

<span class="co"># ...end ends at the Project Gutenberg footer.</span>
stop &lt;-<span class="st"> </span><span class="kw">grep</span>(<span class="st">"^End of Project Gutenberg"</span>, raw) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>

lines &lt;-<span class="st"> </span>raw[start<span class="op">:</span>stop]</code></pre></div>
<p>The novel starts with front matter: a title page, table of contents, introduction, and half title page. Then, a series of chapters follow. We group the lines by section.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the front matter ends at the half title page</span>
half_title &lt;-<span class="st"> </span><span class="kw">grep</span>(<span class="st">"^THE WONDERFUL WIZARD OF OZ"</span>, lines)

<span class="co"># chapters start with "1.", "2.", etc...</span>
chapter &lt;-<span class="st"> </span><span class="kw">grep</span>(<span class="st">"^[[:space:]]*[[:digit:]]+</span><span class="ch">\\</span><span class="st">."</span>, lines)

<span class="co"># ... and appear after the half title page</span>
chapter &lt;-<span class="st"> </span>chapter[chapter <span class="op">&gt;</span><span class="st"> </span>half_title]

<span class="co"># get the section texts (including the front matter)</span>
start &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, chapter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># + 1 to skip title</span>
end &lt;-<span class="st"> </span><span class="kw">c</span>(chapter <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="kw">length</span>(lines))
text &lt;-<span class="st"> </span><span class="kw">mapply</span>(<span class="cf">function</span>(s, e) <span class="kw">paste</span>(lines[s<span class="op">:</span>e], <span class="dt">collapse =</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>), start, end)

<span class="co"># trim leading and trailing white space</span>
text &lt;-<span class="st"> </span><span class="kw">trimws</span>(text)

<span class="co"># discard the front matter</span>
text &lt;-<span class="st"> </span>text[<span class="op">-</span><span class="dv">1</span>]

<span class="co"># get the section titles, removing the prefix ("1.", "2.", etc.)</span>
title &lt;-<span class="st"> </span><span class="kw">sub</span>(<span class="st">"^[[:space:]]*[[:digit:]]+[.][[:space:]]*"</span>, <span class="st">""</span>, lines[chapter])
title &lt;-<span class="st"> </span><span class="kw">trimws</span>(title)</code></pre></div>
</div>
<div id="corpus-object" class="section level2">
<h2 class="hasAnchor">
<a href="#corpus-object" class="anchor"></a>Corpus object</h2>
<p>Now that we have obtained our raw data, we put everything together into a corpus data frame object, constructed via the <code><a href="../reference/corpus_frame.html">corpus_frame()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus_frame.html">corpus_frame</a></span>(title, text)

<span class="co"># set the row names; not necessary but makes results easier to read</span>
<span class="kw">rownames</span>(data) &lt;-<span class="st"> </span><span class="kw">sprintf</span>(<span class="st">"ch%02d"</span>, <span class="kw">seq_along</span>(chapter))</code></pre></div>
<p>The <code><a href="../reference/corpus_frame.html">corpus_frame()</a></code> function behaves similarly to the <code>data.frame</code> function, but expects one of the columns to be named <code>"text"</code>. Note that we do not need to specify <code>stringsAsFactors = FALSE</code> when creating a corpus data frame object. As an alternative to using the <code><a href="../reference/corpus_frame.html">corpus_frame()</a></code> function, we can construct a data frame using some other method (e.g., <code>read.csv</code> or <code>read_ndjson</code>) and use the <code><a href="../reference/corpus_frame.html">as_corpus_frame()</a></code> function.</p>
<p>A corpus data frame object is just a data frame with a column named “text” of type <code>"corpus_text"</code>. When using the <em>corpus</em> library, it is not strictly necessary to use corpus data frame objects as inputs; most functions will accept with character vectors, ordinary data frames, <em>quanteda</em> corpus objects, and <em>tm</em> Corpus objects.. Using a native corpus object gives better printing behavior and allows setting a <code>text_filter</code> attribute to override the default text preprocessing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(data) <span class="co"># better output than printing a data frame, cuts off after 20 rows</span></code></pre></div>
<pre><code>     title                             text                                                         
ch01 The Cyclone                       Dorothy lived in the midst of the great Kansas prairies, wit…
ch02 The Council with the Munchkins    She was awakened by a shock, so sudden and severe that if Do…
ch03 How Dorothy Saved the Scarecrow   When Dorothy was left alone she began to feel hungry.  So sh…
ch04 The Road Through the Forest       After a few hours the road began to be rough, and the walkin…
ch05 The Rescue of the Tin Woodman     When Dorothy awoke the sun was shining through the trees and…
ch06 The Cowardly Lion                 All this time Dorothy and her companions had been walking th…
ch07 The Journey to the Great Oz       They were obliged to camp out that night under a large tree …
ch08 The Deadly Poppy Field            Our little party of travelers awakened the next morning refr…
ch09 The Queen of the Field Mice       "We cannot be far from the road of yellow brick, now," remar…
ch10 The Guardian of the Gate          It was some time before the Cowardly Lion awakened, for he h…
ch11 The Wonderful City of Oz          Even with eyes protected by the green spectacles, Dorothy an…
ch12 The Search for the Wicked Witch   The soldier with the green whiskers led them through the str…
ch13 The Rescue                        The Cowardly Lion was much pleased to hear that the Wicked W…
ch14 The Winged Monkeys                You will remember there was no road--not even a pathway--bet…
ch15 The Discovery of Oz, the Terrible The four travelers walked up to the great gate of Emerald Ci…
ch16 The Magic Art of the Great Humbug Next morning the Scarecrow said to his friends:\n\n"Congratu…
ch17 How the Balloon Was Launched      For three days Dorothy heard nothing from Oz.  These were sa…
ch18 Away to the South                 Dorothy wept bitterly at the passing of her hope to get home…
ch19 Attacked by the Fighting Trees    The next morning Dorothy kissed the pretty green girl good-b…
ch20 The Dainty China Country          While the Woodman was making a ladder from wood which he fou…
⋮    (24 rows total)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(data, <span class="dv">5</span>) <span class="co"># cuts off after 5 rows</span></code></pre></div>
<pre><code>     title                           text                                                           
ch01 The Cyclone                     Dorothy lived in the midst of the great Kansas prairies, with …
ch02 The Council with the Munchkins  She was awakened by a shock, so sudden and severe that if Doro…
ch03 How Dorothy Saved the Scarecrow When Dorothy was left alone she began to feel hungry.  So she …
ch04 The Road Through the Forest     After a few hours the road began to be rough, and the walking …
ch05 The Rescue of the Tin Woodman   When Dorothy awoke the sun was shining through the trees and T…
⋮    (24 rows total)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(data, <span class="op">-</span><span class="dv">1</span>) <span class="co"># prints all rows</span></code></pre></div>
<pre><code>     title                                       text                                               
ch01 The Cyclone                                 Dorothy lived in the midst of the great Kansas pra…
ch02 The Council with the Munchkins              She was awakened by a shock, so sudden and severe …
ch03 How Dorothy Saved the Scarecrow             When Dorothy was left alone she began to feel hung…
ch04 The Road Through the Forest                 After a few hours the road began to be rough, and …
ch05 The Rescue of the Tin Woodman               When Dorothy awoke the sun was shining through the…
ch06 The Cowardly Lion                           All this time Dorothy and her companions had been …
ch07 The Journey to the Great Oz                 They were obliged to camp out that night under a l…
ch08 The Deadly Poppy Field                      Our little party of travelers awakened the next mo…
ch09 The Queen of the Field Mice                 "We cannot be far from the road of yellow brick, n…
ch10 The Guardian of the Gate                    It was some time before the Cowardly Lion awakened…
ch11 The Wonderful City of Oz                    Even with eyes protected by the green spectacles, …
ch12 The Search for the Wicked Witch             The soldier with the green whiskers led them throu…
ch13 The Rescue                                  The Cowardly Lion was much pleased to hear that th…
ch14 The Winged Monkeys                          You will remember there was no road--not even a pa…
ch15 The Discovery of Oz, the Terrible           The four travelers walked up to the great gate of …
ch16 The Magic Art of the Great Humbug           Next morning the Scarecrow said to his friends:\n… 
ch17 How the Balloon Was Launched                For three days Dorothy heard nothing from Oz.  The…
ch18 Away to the South                           Dorothy wept bitterly at the passing of her hope t…
ch19 Attacked by the Fighting Trees              The next morning Dorothy kissed the pretty green g…
ch20 The Dainty China Country                    While the Woodman was making a ladder from wood wh…
ch21 The Lion Becomes the King of Beasts         After climbing down from the china wall the travel…
ch22 The Country of the Quadlings                The four travelers passed through the rest of the …
ch23 Glinda The Good Witch Grants Dorothy's Wish Before they went to see Glinda, however, they were…
ch24 Home Again                                  Aunt Em had just come out of the house to water th…</code></pre>
</div>
<div id="tokenization" class="section level2">
<h2 class="hasAnchor">
<a href="#tokenization" class="anchor"></a>Tokenization</h2>
<p>Text in <em>corpus</em> is represented as a sequence of tokens, each taking a value in a set of types. We can see the tokens for one or more elements using the <code>text_tokens</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_tokens.html">text_tokens</a></span>(data[<span class="st">"ch24"</span>,]) <span class="co"># Chapter 24's tokens</span></code></pre></div>
<pre><code>$ch24
 [1] "aunt"     "em"       "had"      "just"     "come"     "out"      "of"       "the"     
 [9] "house"    "to"       "water"    "the"      "cabbages" "when"     "she"      "looked"  
[17] "up"       "and"      "saw"      "dorothy"  "running"  "toward"   "her"      "."       
[25] "\""       "my"       "darling"  "child"    "!"        "\""       "she"      "cried"   
[33] ","        "folding"  "the"      "little"   "girl"     "in"       "her"      "arms"    
[41] "and"      "covering" "her"      "face"     "with"     "kisses"   "."        "\""      
[49] "where"    "in"       "the"      "world"    "did"      "you"      "come"     "from"    
[57] "?"        "\""       "\""       "from"     "the"      "land"     "of"       "oz"      
[65] ","        "\""       "said"     "dorothy"  "gravely"  "."        "\""       "and"     
[73] "here"     "is"       "toto"     ","        "too"      "."        "and"      "oh"      
[81] ","        "aunt"     "em"       "!"        "i'm"      "so"       "glad"     "to"      
[89] "be"       "at"       "home"     "again"    "!"        "\""      </code></pre>
<p>The default behavior is to normalize tokens by changing the cases of the letters to lower case. A <code>text_filter</code> object controls the rules for segmentation and normalization. We can inspect the text filter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data)</code></pre></div>
<pre><code>Text filter with the following options:

    map_case: TRUE
    map_quote: TRUE
    remove_ignorable: TRUE
    stemmer: NULL
    stem_dropped: FALSE
    stem_except: NULL
    combine:  chr [1:155] "A." "A.D." "a.m." "A.M." "A.S." "AA." "AB." "Abs." "AD." "Adj." ...
    drop_letter: FALSE
    drop_number: FALSE
    drop_punct: FALSE
    drop_symbol: FALSE
    drop: NULL
    drop_except: NULL
    sent_crlf: FALSE
    sent_suppress:  chr [1:155] "A." "A.D." "a.m." "A.M." "A.S." "AA." "AB." "Abs." "AD." ...</code></pre>
<p>We can change the text filter properties:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data)<span class="op">$</span>map_case &lt;-<span class="st"> </span><span class="ot">FALSE</span>
<span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data)<span class="op">$</span>drop_punct &lt;-<span class="st"> </span><span class="ot">TRUE</span>
<span class="kw"><a href="../reference/text_tokens.html">text_tokens</a></span>(data[<span class="st">"ch24"</span>,])</code></pre></div>
<pre><code>$ch24
 [1] "Aunt"     "Em"       "had"      "just"     "come"     "out"      "of"       "the"     
 [9] "house"    "to"       "water"    "the"      "cabbages" "when"     "she"      "looked"  
[17] "up"       "and"      "saw"      "Dorothy"  "running"  "toward"   "her"      NA        
[25] NA         "My"       "darling"  "child"    NA         NA         "she"      "cried"   
[33] NA         "folding"  "the"      "little"   "girl"     "in"       "her"      "arms"    
[41] "and"      "covering" "her"      "face"     "with"     "kisses"   NA         NA        
[49] "Where"    "in"       "the"      "world"    "did"      "you"      "come"     "from"    
[57] NA         NA         NA         "From"     "the"      "Land"     "of"       "Oz"      
[65] NA         NA         "said"     "Dorothy"  "gravely"  NA         NA         "And"     
[73] "here"     "is"       "Toto"     NA         "too"      NA         "And"      "oh"      
[81] NA         "Aunt"     "Em"       NA         "I'm"      "so"       "glad"     "to"      
[89] "be"       "at"       "home"     "again"    NA         NA        </code></pre>
<p>To restore the defaults, set the text filter to <code>NULL</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data) &lt;-<span class="st"> </span><span class="ot">NULL</span></code></pre></div>
<p>In addition to mapping case and quotes (the defaults), I’m going to drop punctuation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data) &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>The tokenizer allows for precise controlling over token dropping and token stemming. It also allows combining two or more words into a single token as in the following example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_tokens.html">text_tokens</a></span>(<span class="st">"I live in New York City, New York"</span>,
            <span class="dt">combine =</span> <span class="kw">c</span>(<span class="st">"new york"</span>, <span class="st">"new york city"</span>))</code></pre></div>
<pre><code>[[1]]
[1] "i"             "live"          "in"            "new york city" ","             "new york"     </code></pre>
<p>This example using the optional second argument to <code>text_tokens</code> to override the first argument’s default text filter. Here, instances of “new york” and “new york city” get replaced by single tokens, with the longest match taking precedence. See the documentation for <code>text_tokens</code> describes the full tokenization process.</p>
</div>
<div id="texts-as-sequences" class="section level2">
<h2 class="hasAnchor">
<a href="#texts-as-sequences" class="anchor"></a>Texts as sequences</h2>
<p>The mental model of the <em>corpus</em> package is that a text is s sequence of tokens, some of which are dropped (<code>NA</code>). Every object has a <code><a href="../reference/text_filter.html">text_filter()</a></code> property defining its token boundaries. The default token filter transforms the text to Unicode composed normal form (NFC), applies Unicode case folding, and maps curly quotes to straight quotes. Text objects, created with <code>as_corpus_text</code> or <code>as_corpus</code> can have custom text filters. You cannot set the text filter for a character vector. However, all <em>corpus</em> text functions accept a <code>filter</code> argument to override the input object’s text filter (this is demonstrated in the “New York City” example in the previous section).</p>
<p>To find out the length of a text, as measured in dropped and non-dropped tokens, use the <code>text_length</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_tokens.html">text_tokens</a></span>(<span class="st">"One, two, three!"</span>, <span class="dt">filter =</span> <span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>[[1]]
[1] "one"   NA      "two"   NA      "three" NA     </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_tokens.html">text_length</a></span>(<span class="st">"One, two, three!"</span>, <span class="dt">filter =</span> <span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>[1] 6</code></pre>
<p>You can set subsequences of consecutive tokens using the <code>text_sub</code> function. This function accepts two arguments specifying the start and then end token position. The following example extracts the subsequences from positions 2 to 4:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(<span class="kw">c</span>(<span class="st">"One, two, three!"</span>, <span class="st">"4 5 6 7 8 9 10"</span>), <span class="dv">2</span>, <span class="dv">4</span>,
         <span class="dt">filter =</span> <span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>[1] ", two, "
[2] "5 6 7 " </code></pre>
<p>Negative indices count from the end of the sequence, with <code>-1</code> denoting the last token.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># last 2 tokens</span>
<span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(<span class="kw">c</span>(<span class="st">"One, two, three!"</span>, <span class="st">"4 5 6 7 8 9 10"</span>), <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>,
         <span class="dt">filter =</span> <span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>[1] "three!"
[2] "9 10"  </code></pre>
<p>Note that <code>text_length</code> and <code>text_sub</code> count both dropped and non-dropped tokens.</p>
<p>Here’s how to get the last 10 tokens in each chapter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(data, <span class="op">-</span><span class="dv">10</span>)</code></pre></div>
<pre><code>ch01 "Dorothy soon closed her eyes and fell fast asleep."         
ch02 "way, and was not surprised in the least."                   
ch03 "the Scarecrow; \"it's a lighted match.\""                   
ch04 "in another\ncorner and waited patiently until morning came."
ch05 ", and could not live unless she was fed."                   
ch06 "heart of course I needn't mind so much.\""                  
ch07 "soon send her back to her own home again."                  
ch08 "and waited for the fresh breeze to waken her."              
ch09 "near by, which she\nate for her dinner."                    
ch10 "the portal into the streets of the Emerald City."           
ch11 "of a hen that had laid a\ngreen egg."                       
ch12 "they were no longer prisoners in a strange\nland."          
ch13 "cheers and many good wishes to\ncarry with them."           
ch14 "it was you brought away that wonderful Cap!\""              
ch15 "he did she was willing to forgive him everything."          
ch16 "I don't know\nhow it can be done.\""                        
ch17 "the Wonderful\nWizard, and would not be comforted."         
ch18 ", for it will be a long journey.\""                         
ch19 "for we certainly must\nclimb over the wall.\""              
ch20 "things in the\nworld than being a Scarecrow.\""             
⋮    (24 entries total)</code></pre>
<p>In this example, we do not specify the ending position, so it defaults to <code>-1</code>.</p>
</div>
<div id="text-statistics" class="section level2">
<h2 class="hasAnchor">
<a href="#text-statistics" class="anchor"></a>Text statistics</h2>
<div id="token-type-and-sentence-counts" class="section level3">
<h3 class="hasAnchor">
<a href="#token-type-and-sentence-counts" class="anchor"></a>Token, type, and sentence counts</h3>
<p>The <code>text_ntoken</code>, <code>text_ntype</code>, and <code>text_nsentence</code> functions return the numbers of non-dropped tokens, unique types, and sentences, respectively, in a set of texts. We can use these functions to get an overview of the section lengths and lexical diversities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_tokens.html">text_ntoken</a></span>(data)</code></pre></div>
<pre><code>ch01 ch02 ch03 ch04 ch05 ch06 ch07 ch08 ch09 ch10 ch11 ch12 ch13 ch14 ch15 ch16 ch17 ch18 ch19 ch20 
1142 2001 1955 1434 2054 1498 1798 1926 1383 1950 3608 3667 1188 1885 2760  921 1151 1162 1011 1500 
ch21 ch22 ch23 ch24 
 891  931 1250   74 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_types.html">text_ntype</a></span>(data)</code></pre></div>
<pre><code>ch01 ch02 ch03 ch04 ch05 ch06 ch07 ch08 ch09 ch10 ch11 ch12 ch13 ch14 ch15 ch16 ch17 ch18 ch19 ch20 
 414  567  570  454  524  458  530  517  466  539  782  788  404  557  638  316  400  379  401  511 
ch21 ch22 ch23 ch24 
 360  364  404   56 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_split.html">text_nsentence</a></span>(data)</code></pre></div>
<pre><code>ch01 ch02 ch03 ch04 ch05 ch06 ch07 ch08 ch09 ch10 ch11 ch12 ch13 ch14 ch15 ch16 ch17 ch18 ch19 ch20 
  57  131  122   81  108   96   91  102   73  110  190  176   49  100  188   71   72   87   53   88 
ch21 ch22 ch23 ch24 
  50   50   63    8 </code></pre>
<p>The <code>text_stats</code> function computes all three counts and presents the results in a data frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">stats &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_stats.html">text_stats</a></span>(data)
<span class="kw">print</span>(stats, <span class="op">-</span><span class="dv">1</span>) <span class="co"># print all rows instead of truncating at 20</span></code></pre></div>
<pre><code>     tokens types sentences
ch01   1142   414        57
ch02   2001   567       131
ch03   1955   570       122
ch04   1434   454        81
ch05   2054   524       108
ch06   1498   458        96
ch07   1798   530        91
ch08   1926   517       102
ch09   1383   466        73
ch10   1950   539       110
ch11   3608   782       190
ch12   3667   788       176
ch13   1188   404        49
ch14   1885   557       100
ch15   2760   638       188
ch16    921   316        71
ch17   1151   400        72
ch18   1162   379        87
ch19   1011   401        53
ch20   1500   511        88
ch21    891   360        50
ch22    931   364        50
ch23   1250   404        63
ch24     74    56         8</code></pre>
<p>We can see that the last chapter is the shortest, with 74 tokens, 56 unique types, and 8 sentences. Chapter 12 is the longest.</p>
</div>
<div id="application-testing-heaps-law" class="section level3">
<h3 class="hasAnchor">
<a href="#application-testing-heaps-law" class="anchor"></a>Application: Testing Heaps’ law</h3>
<p><a href="https://en.wikipedia.org/wiki/Heaps%27_law" title="Heap's law">Heaps’ law</a> says that the logarithm of the number of unique types is a linear function of the number of tokens. We can test this law formally with a regression analysis.</p>
<p>In this analysis, we will exclude the last chapter (Chapter 24), because it is much shorter than the others and has a disproportionate influence on the fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subset &lt;-<span class="st"> </span><span class="kw">row.names</span>(stats) <span class="op">!=</span><span class="st"> "ch24"</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(types) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(tokens), stats, subset)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>
Call:
lm(formula = log(types) ~ log(tokens), data = stats, subset = subset)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.113568 -0.031623  0.006547  0.034415  0.086886 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.94872    0.19082   10.21 1.34e-09 ***
log(tokens)  0.57441    0.02591   22.17 4.73e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.04894 on 21 degrees of freedom
Multiple R-squared:  0.959, Adjusted R-squared:  0.9571 
F-statistic: 491.6 on 1 and 21 DF,  p-value: 4.73e-16</code></pre>
<p>We can also inspect the relation visually</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(<span class="kw">log</span>(types) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(tokens), stats, <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">subset =</span> subset)
<span class="kw">abline</span>(model, <span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="kw">plot</span>(<span class="kw">log</span>(stats<span class="op">$</span>tokens[subset]), <span class="kw">rstandard</span>(model), <span class="dt">col =</span> <span class="dv">2</span>,
     <span class="dt">xlab =</span> <span class="st">"log(tokens)"</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

outlier &lt;-<span class="st"> </span><span class="kw">abs</span>(<span class="kw">rstandard</span>(model)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span>
<span class="kw">text</span>(<span class="kw">log</span>(stats<span class="op">$</span>tokens)[subset][outlier], <span class="kw">rstandard</span>(model)[outlier],
     <span class="kw">row.names</span>(stats)[subset][outlier], <span class="dt">cex =</span> <span class="fl">0.75</span>, <span class="dt">adj =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.5</span>),
     <span class="dt">col =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="corpus-heapslaw-1.png" alt="Heaps’ Law"><p class="caption">Heaps’ Law</p>
</div>
<p>The analysis tells us that Heap’s law accurately characterizes the lexical diversity (type-to-token ratio) for the main chapters in <em>The Wizard of Oz</em>. The number of unique types grows roughly as the number of tokens raised to the power <code>0.6</code>.</p>
<p>The one chapter with an unusually low lexical diversity is Chapter 16. This chapter contains mostly dialogue between Oz and Dorothy’s simple-minded companions (the Scarecrow, Tin Woodman, and Lion).</p>
</div>
</div>
<div id="term-statistics" class="section level2">
<h2 class="hasAnchor">
<a href="#term-statistics" class="anchor"></a>Term statistics</h2>
<div id="counts-and-prevalence" class="section level3">
<h3 class="hasAnchor">
<a href="#counts-and-prevalence" class="anchor"></a>Counts and prevalence</h3>
<p>We get term statistics using the <code>term_stats</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data)</code></pre></div>
<pre><code>   term    count support
1  the      2922      24
2  and      1661      24
3  to       1108      24
4  of        824      24
5  you       489      24
6  in        478      24
7  dorothy   345      24
8  so        307      24
9  with      271      24
10 had       263      24
11 is        260      24
12 at        253      24
13 when      158      24
14 up        106      24
15 again      87      24
16 a         803      23
17 was       501      23
18 he        453      23
19 it        420      23
20 her       410      23
⋮  (2878 rows total)</code></pre>
<p>This returns a data frame with each row giving the count and support for each term. The “count” is the total number of occurrences of the term in the corpus. The “support” is the number of texts containing the term. In the output above, we can see that “the” is the most common term, appearing 2922 times total in all 24 chapters. The pronoun “her” is the 20th most common term, appearing in all but one chapter.</p>
<p>The most common words are English function words, commonly known as “stop” words. We can exclude these terms from the tally using the <code>subset</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data, <span class="dt">subset =</span> <span class="op">!</span>term <span class="op">%in%</span><span class="st"> </span>stopwords_en)</code></pre></div>
<pre><code>   term      count support
1  dorothy     345      24
2  said        332      23
3  little      139      22
4  one         125      22
5  asked       114      22
6  came        104      22
7  back         98      22
8  girl         93      22
9  toto         90      22
10 get          85      22
11 now          82      22
12 answered     78      22
13 scarecrow   217      21
14 upon         85      21
15 shall        82      21
16 go           72      21
17 looked       61      21
18 time         43      21
19 great       138      20
20 head         90      20
⋮  (2734 rows total)</code></pre>
<p>The character names “dorothy”, “toto”, and “scarecrow” show up at the top of the list of the most common terms.</p>
</div>
<div id="higher-order-n-grams" class="section level3">
<h3 class="hasAnchor">
<a href="#higher-order-n-grams" class="anchor"></a>Higher-order n-grams</h3>
<p>Beyond searching for single-type terms, we can also search for multi-type terms (“n-grams”).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data, <span class="dt">ngrams =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>   term                            count support
1  scarecrow and the tin woodman      13       9
2  the scarecrow and the tin          13       9
3  the wicked witch of the            20       7
4  the road of yellow brick           12       7
5  wicked witch of the west           12       6
6  soldier with the green whiskers     8       6
7  the soldier with the green          8       6
8  send me back to kansas              6       6
9  to get back to kansas               7       5
10 the tin woodman and the             6       5
11 the guardian of the gates          10       4
12 in the middle of the                8       4
13 wicked witch of the east            8       4
14 until they came to the              6       4
15 to the land of the                  5       4
16 and the tin woodman and             4       4
17 in the midst of a                   4       4
18 to give me a heart                  4       4
19 to send me back to                  4       4
20 what shall we do now                4       4
⋮  (20230 rows total)</code></pre>
<p>The <code>types</code> argument allows us to request the component types in the result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data, <span class="dt">ngrams =</span> <span class="dv">3</span>, <span class="dt">types =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>   term                type1     type2     type3     count support
1  the tin woodman     the       tin       woodman     112      18
2  said the scarecrow  said      the       scarecrow    36      16
3  the emerald city    the       emerald   city         53      14
4  back to kansas      back      to        kansas       28      14
5  as soon as          as        soon      as           17      13
6  and the lion        and       the       lion         24      12
7  the little girl     the       little    girl         21      12
8  and the tin         and       the       tin          19      12
9  and the scarecrow   and       the       scarecrow    21      11
10 the scarecrow and   the       scarecrow and          19      11
11 the wicked witch    the       wicked    witch        56      10
12 said the tin        said      the       tin          19      10
13 the cowardly lion   the       cowardly  lion         19      10
14 the land of         the       land      of           19      10
15 they came to        they      came      to           19      10
16 scarecrow and the   scarecrow and       the          17      10
17 get back to         get       back      to           15      10
18 asked the scarecrow asked     the       scarecrow    10      10
19 witch of the        witch     of        the          30       9
20 to the emerald      to        the       emerald      21       9
⋮  (23596 rows total)</code></pre>
<p>Here are the most common 2-, 3-grams starting with “dorothy”, where the second type is not a function word</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data, <span class="dt">ngrams =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">types =</span> <span class="ot">TRUE</span>,
           <span class="dt">subset =</span> type1 <span class="op">==</span><span class="st"> "dorothy"</span> <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span>type2 <span class="op">%in%</span><span class="st"> </span>stopwords_en)</code></pre></div>
<pre><code>   term              type1   type2     type3 count support
1  dorothy went      dorothy went      &lt;NA&gt;      6       6
2  dorothy looked    dorothy looked    &lt;NA&gt;      6       5
3  dorothy said      dorothy said      &lt;NA&gt;      5       5
4  dorothy saw       dorothy saw       &lt;NA&gt;      5       5
5  dorothy walked    dorothy walked    &lt;NA&gt;      4       4
6  dorothy went to   dorothy went      to        4       4
7  dorothy asked     dorothy asked     &lt;NA&gt;      3       3
8  dorothy found     dorothy found     &lt;NA&gt;      3       3
9  dorothy looked at dorothy looked    at        3       3
10 dorothy picked    dorothy picked    &lt;NA&gt;      3       3
11 dorothy sat       dorothy sat       &lt;NA&gt;      3       3
12 dorothy thought   dorothy thought   &lt;NA&gt;      3       3
13 dorothy put       dorothy put       &lt;NA&gt;      3       2
14 dorothy stood     dorothy stood     &lt;NA&gt;      3       2
15 dorothy ate       dorothy ate       &lt;NA&gt;      2       2
16 dorothy awoke     dorothy awoke     &lt;NA&gt;      2       2
17 dorothy awoke the dorothy awoke     the       2       2
18 dorothy carried   dorothy carried   &lt;NA&gt;      2       2
19 dorothy earnestly dorothy earnestly &lt;NA&gt;      2       2
20 dorothy entered   dorothy entered   &lt;NA&gt;      2       2
⋮  (202 rows total)</code></pre>
</div>
</div>
<div id="searching-for-terms" class="section level2">
<h2 class="hasAnchor">
<a href="#searching-for-terms" class="anchor"></a>Searching for terms</h2>
<p>Now that we have identified common terms, we might be interested in seeing where they appear. For this, we use the <code>text_locate</code> function.</p>
<p>Here are all instances of the term “dorothy looked”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="st">"dorothy looked"</span>)</code></pre></div>
<pre><code>  text                 before                    instance                     after                 
1 ch02 …out from\nunder a block of wood."\n\n Dorothy looked , and gave a little cry of fright.  Th…
2 ch05 …, as if he could not stir at all.\n\n Dorothy looked  at him in amazement, and so did the S…
3 ch12 …ve a loud cry of fear, and then, as\n Dorothy looked  at her in wonder, the Witch began to …
4 ch14 … all the mice hurrying after her.\n\n Dorothy looked  inside the Golden Cap and saw some wo…
5 ch14 …s the Monkey King finished his story  Dorothy looked  down and saw the\ngreen, shining wall…
6 ch16 …rmly he went back to his friends.\n\n Dorothy looked  at him curiously.  His head was quite…</code></pre>
<p>Note that we match against the type of the token, not the raw token itself, so we are able to detect capitalized “Dorothy”. This is especially useful when we want to search for a stemmed token. Here are all instances of tokens that stem to “scream”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="st">"scream"</span>, <span class="dt">stemmer =</span> <span class="st">"english"</span>)</code></pre></div>
<pre><code>  text                  before                   instance                   after                   
1 ch01 … by the child's laughter that she would   scream  \nand press her hand upon her heart whene…
2 ch01 …close at hand.\n\n"Quick, Dorothy!" she  screamed .  "Run for the cellar!"\n\nToto jumped o…
3 ch07 … loud\nand terrible a roar that Dorothy  screamed  and the Scarecrow fell over\nbackward, w…
4 ch12  …away.\n\n"See what you have done!" she  screamed .  "In a minute I shall melt\naway."\n\n"…
5 ch17 …he air without her.\n\n"Come back!" she  screamed .  "I want to go, too!"\n\n"I can't come …</code></pre>
<p>If we would like, we can search for multiple phrases at the same time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="kw">c</span>(<span class="st">"wicked witch"</span>, <span class="st">"toto"</span>, <span class="st">"oz"</span>))</code></pre></div>
<pre><code>   text                 before                    instance                    after                 
1  ch01 …d solemn, and rarely spoke.\n\nIt was      Toto      that made Dorothy laugh, and saved he…
2  ch01 … as gray\nas her other surroundings.       Toto      was not gray; he was a little black\n…
3  ch01  …either side of his funny, wee nose.       Toto      played all day long, and\nDorothy pla…
4  ch01 …sual.  Dorothy stood in the door with      Toto      in her arms, and looked at\nthe sky t…
5  ch01 …e screamed.  "Run for the cellar!"\n\n     Toto      jumped out of Dorothy's arms and hid …
6  ch01 …he small, dark\nhole.  Dorothy caught      Toto      at last and started to follow her aun…
7  ch01 …d gently, like a baby in a cradle.\n\n     Toto      did not like it.  He ran about the ro…
8  ch01 …ed to\nsee what would happen.\n\nOnce      Toto      got too near the open trap door, and …
9  ch01 …fall.  She crept to the hole,\ncaught      Toto      by the ear, and dragged him into the …
10 ch01 …o her bed, and lay down upon it; and\n     Toto      followed and lay down beside her.\n\n…
11 ch02 …th and wonder what had happened; and\n     Toto      put his cold little nose into her fac…
12 ch02 …om.  She sprang from her bed and with      Toto      at her heels ran\nand opened the door…
13 ch02 …grateful to you for having killed the  Wicked Witch  of the\nEast, and for setting our peo…
14 ch02 …eress, and saying she had\nkilled the  Wicked Witch  of the East?  Dorothy was an innocent…
15 ch02 … she?" asked Dorothy.\n\n"She was the  Wicked Witch  of the East, as I said," answered the…
16 ch02 … in this land of the East\n where the  Wicked Witch  ruled."\n\n"Are you a Munchkin?" aske…
17 ch02 …love me.  I am not as powerful as the  Wicked Witch  was who\nruled here, or I should have…
18 ch02 … only four witches in all the Land of       Oz      , and two of them,\nthose who live in …
19 ch02 … killed one of them, there is but one  Wicked Witch \nin all the Land of Oz--the one who l…
20 ch02 … one Wicked Witch\nin all the Land of       Oz      --the one who lives in the West."\n\n"…
⋮  (303 rows total)</code></pre>
<p>We can also request that the results be returned in random order, using the <code><a href="../reference/text_locate.html">text_sample()</a></code> function. This function takes the results from <code><a href="../reference/text_locate.html">text_locate()</a></code> and randomly orders the rows; this is useful for inspecting a random sample of the matches:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_sample</a></span>(data, <span class="kw">c</span>(<span class="st">"wicked witch"</span>, <span class="st">"toto"</span>, <span class="st">"oz"</span>))</code></pre></div>
<pre><code>   text                 before                    instance                    after                 
1  ch17 …ket just touched the\nground.\n\nThen       Oz       got into the basket and said to all t…
2  ch06 … are so tender of?"\n\n"He is my dog,      Toto     ," answered Dorothy.\n\n"Is he made of…
3  ch10  …"Why do you wish to see the terrible       Oz      ?" asked the man.\n\n"I want him to gi…
4  ch12 … friends.\n\n"Which road leads to the  Wicked Witch  of the West?" asked Dorothy.\n\n"Ther…
5  ch24 …" said Dorothy gravely.  "And here is      Toto     , too.\nAnd oh, Aunt Em!  I'm so glad …
6  ch05 …e was scarcely enough for herself and      Toto      for the day.\n\nWhen she had finished…
7  ch17 …d\nthen a strip of emerald green; for       Oz       had a fancy to make the balloon\nin d…
8  ch18 …I should like to cry a little because       Oz       is gone,\nif you will kindly wipe awa…
9  ch12 …he would cry bitterly for hours, with      Toto      sitting at her feet and\nlooking into…
10 ch12 …came out of the dark sky to show\nthe  Wicked Witch  surrounded by a crowd of monkeys, eac…
11 ch02 … killed one of them, there is but one  Wicked Witch \nin all the Land of Oz--the one who l…
12 ch23 …o the Emerald City," he replied, "for       Oz       has made me\nits ruler and the people…
13 ch03 ….  "If you will come with me I'll ask       Oz       to do all he can for\nyou."\n\n"Thank…
14 ch13 …ion was much pleased to hear that the  Wicked Witch  had\nbeen melted by a bucket of water…
15 ch10 …m that pleases him.  But who the real       Oz      \nis, when he is in his own form, no l…
16 ch15 …nt into the Throne Room\nof the Great       Oz      .\n\nOf course each one of them expect…
17 ch11 … the Wicked Witch of the East," said\n      Oz      .\n\n"That just happened," returned Do…
18 ch14 … they sat down and looked at her, and      Toto      found that\nfor the first time in his…
19 ch18 …ver crossed the\ndesert, unless it is       Oz       himself."\n\n"Is there no one who can…
20 ch10 …ity," said Dorothy, "to see the Great       Oz      ."\n\n"Oh, indeed!" exclaimed the man.…
⋮  (303 rows total)</code></pre>
<p>Other functions allow counting term occurrences, testing for whether a term appears in a text, and getting the subset of texts containing a term:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_count</a></span>(data, <span class="st">"the great oz"</span>)</code></pre></div>
<pre><code>ch01 ch02 ch03 ch04 ch05 ch06 ch07 ch08 ch09 ch10 ch11 ch12 ch13 ch14 ch15 ch16 ch17 ch18 ch19 ch20 
   0    0    3    1    1    1    0    0    0    5    3    1    0    0    2    0    0    0    0    0 
ch21 ch22 ch23 ch24 
   0    0    0    0 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_detect</a></span>(data, <span class="st">"the great oz"</span>)</code></pre></div>
<pre><code> ch01  ch02  ch03  ch04  ch05  ch06  ch07  ch08  ch09  ch10  ch11  ch12  ch13  ch14  ch15  ch16 
FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE  TRUE FALSE 
 ch17  ch18  ch19  ch20  ch21  ch22  ch23  ch24 
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_subset</a></span>(data, <span class="st">"the great oz"</span>)</code></pre></div>
<pre><code>ch03 "When Dorothy was left alone she began to feel hungry.  So she went to\nthe cupboard and cut …"
ch04 "After a few hours the road began to be rough, and the walking grew so\ndifficult that the Sc…"
ch05 "When Dorothy awoke the sun was shining through the trees and Toto had\nlong been out chasing…"
ch06 "All this time Dorothy and her companions had been walking through the\nthick woods.  The roa…"
ch10 "It was some time before the Cowardly Lion awakened, for he had lain\namong the poppies a lon…"
ch11 "Even with eyes protected by the green spectacles, Dorothy and her\nfriends were at first daz…"
ch12 "The soldier with the green whiskers led them through the streets of the\nEmerald City until …"
ch15 "The four travelers walked up to the great gate of Emerald City and rang\nthe bell.  After ri…"</code></pre>
</div>
<div id="segmenting-text" class="section level2">
<h2 class="hasAnchor">
<a href="#segmenting-text" class="anchor"></a>Segmenting text</h2>
<div id="sentences-and-blocks-of-tokens" class="section level3">
<h3 class="hasAnchor">
<a href="#sentences-and-blocks-of-tokens" class="anchor"></a>Sentences and blocks of tokens</h3>
<p><em>Corpus</em> can split text into blocks of sentences or tokens using the <code>text_split</code> function. By default, this function splits into sentences. Here, for example, are the last 10 sentences in the book:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(<span class="kw"><a href="../reference/text_split.html">text_split</a></span>(data), <span class="dv">10</span>)</code></pre></div>
<pre><code>     parent index text                                                                              
2207 ch23      62 Dorothy stood up and found she was in her stocking-feet.                          
2208 ch23      63 For the\nSilver Shoes had fallen off in her flight through the air, and were\nlos…
2209 ch24       1 Aunt Em had just come out of the house to water the cabbages when she\nlooked up …
2210 ch24       2 "My darling child!"                                                               
2211 ch24       3 she cried, folding the little girl in her arms and\ncovering her face with kisses…
2212 ch24       4 "Where in the world did you come from?"\n\n                                       
2213 ch24       5 "From the Land of Oz," said Dorothy gravely.                                      
2214 ch24       6 "And here is Toto, too.\n                                                         
2215 ch24       7 And oh, Aunt Em!                                                                  
2216 ch24       8 I'm so glad to be at home again!"                                                 </code></pre>
<p>The result of <code>text_split</code> is a data frame, with one row for each segment identifying the parent text (as a factor), the index of the segment in the parent text (an integer), and the segment text.</p>
<p>The second argument to <code>text_split</code> specifies, the units, “sentences” or “tokens”. The third argument specifies the maximum segment size, defaulting to one. Each text gets divided into approximately equal-sized segments, with no segment being larger than the specified size.</p>
<p>Here is an example of splitting two texts into segments of size at most four tokens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_split.html">text_split</a></span>(<span class="kw">c</span>(<span class="st">"the wonderful wizard of oz"</span>, <span class="kw">paste</span>(LETTERS, <span class="dt">collapse =</span> <span class="st">" "</span>)),
           <span class="st">"tokens"</span>, <span class="dv">4</span>)</code></pre></div>
<pre><code>  parent index text                 
1 1          1 the wonderful wizard 
2 1          2 of oz                
3 2          1 A B C D              
4 2          2 E F G H              
5 2          3 I J K L              
6 2          4 M N O P              
7 2          5 Q R S T              
8 2          6 U V W                
9 2          7 X Y Z                </code></pre>
</div>
<div id="application-witch-tracking" class="section level3">
<h3 class="hasAnchor">
<a href="#application-witch-tracking" class="anchor"></a>Application: Witch tracking</h3>
<p>We can combine <code>text_split</code> with <code>text_count</code> to measure the occurrences rates for the term “witch” over the course of the novel. Here, the chunks have varying sizes, so we look at the rates rather than the raw counts.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chunks &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_split.html">text_split</a></span>(data, <span class="st">"tokens"</span>, <span class="dv">500</span>)
size &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_tokens.html">text_ntoken</a></span>(chunks)

unit &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="co"># rate per 1000 tokens</span>
count &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_locate.html">text_count</a></span>(chunks, <span class="st">"witch"</span>)
rate &lt;-<span class="st">  </span>count <span class="op">/</span><span class="st"> </span>size <span class="op">*</span><span class="st"> </span>unit

i &lt;-<span class="st"> </span><span class="kw">seq_along</span>(rate)
<span class="kw">plot</span>(i, rate, <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">xlab =</span> <span class="st">"Segment"</span>,
     <span class="dt">ylab =</span> <span class="st">"Rate \u00d7 1000"</span>,
     <span class="dt">main =</span> <span class="kw">paste</span>(<span class="kw">dQuote</span>(<span class="st">"witch"</span>), <span class="st">"Occurrences"</span>), <span class="dt">col =</span> <span class="dv">2</span>)
<span class="kw">points</span>(i, rate, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">cex =</span> <span class="fl">0.5</span>, <span class="dt">col =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="corpus-witch-occurrences-1.png" alt="witch Occurences"><p class="caption">‘witch’ Occurences</p>
</div>
<p>We can see Dorothy’s house landing on the Wicked Witch of the East in the and the subsequent fallout in the beginning of the novel. Around segment 40, we see the events surrounding Dorothy’s battle with the Wicked Witch of the West. At the end of the novel, we see the Good Witch of the South appearing to help Dorothy get home.</p>
</div>
</div>
<div id="term-frequency-matrix" class="section level2">
<h2 class="hasAnchor">
<a href="#term-frequency-matrix" class="anchor"></a>Term frequency matrix</h2>
<p>Many downstream text analysis tasks require tabulating a matrix of text-term occurrence counts. We can get such a matrix using the <code>term_matrix</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_matrix.html">term_matrix</a></span>(data)
<span class="kw">dim</span>(x)</code></pre></div>
<pre><code>[1]   24 2878</code></pre>
<p>This function returns a sparse matrix object from the <em>Matrix</em> package. In the default usage, the rows of the matrix correspond to texts, and the columns correspond to terms. For a “term-by-document” matrix, you can use the <code>transpose</code> option:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xt &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_matrix.html">term_matrix</a></span>(data, <span class="dt">transpose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>You can include n-grams in the result if you would like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_matrix.html">term_matrix</a></span>(data, <span class="dt">ngrams =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>) <span class="co"># 1-, 2-, and 3-grams</span></code></pre></div>
<p>Or, you can specify the columns to include in the matrix</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(x &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_matrix.html">term_matrix</a></span>(data, <span class="dt">select =</span> <span class="kw">c</span>(<span class="st">"dorothy"</span>, <span class="st">"toto"</span>, <span class="st">"wicked witch"</span>, <span class="st">"the great oz"</span>)))</code></pre></div>
<pre><code>24 x 4 sparse Matrix of class "dgCMatrix"
     dorothy toto wicked witch the great oz
ch01      15   10            .            .
ch02      31    3            8            .
ch03      24   14            3            3
ch04       8    3            .            1
ch05      13    4            5            1
ch06      12    9            .            1
ch07      13    4            .            .
ch08      16    5            1            .
ch09       5    5            .            .
ch10      18    6            .            5
ch11      32    1           11            3
ch12      33    7           19            1
ch13      11    1            2            .
ch14      15    2            2            .
ch15      18    2            6            2
ch16       3    .            .            .
ch17      10    2            .            .
ch18      15    .            .            .
ch19       8    2            .            .
ch20      20    3            .            .
ch21       4    2            .            .
ch22       7    2            .            .
ch23      12    2            1            .
ch24       2    1            .            .</code></pre>
<p>The columns of <code>x</code> will be in the same order as specified by the <code>select</code> argument. Note that we can request higher-order n-grams.</p>
</div>
<div id="emotion-lexicon" class="section level2">
<h2 class="hasAnchor">
<a href="#emotion-lexicon" class="anchor"></a>Emotion lexicon</h2>
<p><em>Corpus</em> provides a lexicon of terms connoting emotional affect, the <a href="http://wndomains.fbk.eu/wnaffect.html" title="WordNet-Affect">WordNet Affect Lexicon</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">affect_wordnet</code></pre></div>
<pre><code>   term             pos  category emotion 
1  jollity          NOUN Joy      Positive
2  joviality        NOUN Joy      Positive
3  chaff            VERB Joy      Positive
4  kid              VERB Joy      Positive
5  banter           VERB Joy      Positive
6  jolly            VERB Joy      Positive
7  merry            ADJ  Joy      Positive
8  jovial           ADJ  Joy      Positive
9  jolly            ADJ  Joy      Positive
10 jocund           ADJ  Joy      Positive
11 gay              ADJ  Joy      Positive
12 mirthful         ADJ  Joy      Positive
13 riotously        ADV  Joy      Positive
14 exuberantly      ADV  Joy      Positive
15 expansively      ADV  Joy      Positive
16 ebulliently      ADV  Joy      Positive
17 exuberance       NOUN Joy      Positive
18 lightheartedness NOUN Joy      Positive
19 carefreeness     NOUN Joy      Positive
20 lightsomeness    NOUN Joy      Positive
⋮  (1641 rows total)</code></pre>
<p>This lexicon classifies a large set of terms correlated with emotional affect into four main categories: “Positive”, “Negative”, “Ambiguous”, and “Neutral”, and a variety of sub-categories. Here is a summary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(affect_wordnet)</code></pre></div>
<pre><code>     term             pos         category        emotion   
 Length:1641        NOUN:532   Dislike:338   Positive :541  
 Class :character   ADJ :642   Sadness:199   Negative :978  
 Mode  :character   VERB:267   Joy    :191   Neutral  : 32  
                    ADV :200   Fear   :171   Ambiguous: 90  
                               Liking :106                  
                               Anxiety: 97                  
                               (Other):539                  </code></pre>
<p>Here are the term counts broken down by category:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">with</span>(affect_wordnet, <span class="kw">table</span>(category, emotion))</code></pre></div>
<pre><code>              emotion
category       Positive Negative Neutral Ambiguous
  Joy               191        0       0         0
  Love               40        0       0         0
  Affection          20        0       0         0
  Liking            106        0       0         0
  Enthusiasm         27        0       0         0
  Gratitude           8        0       0         0
  Pride              22        0       0         0
  Levity             14        0       0         0
  Calmness           64        0       0         0
  Fearlessness       19        0       0         0
  Expectation         7        0       0        18
  Fear                7      151       0        13
  Hope               16        0       0         0
  Sadness             0      199       0         0
  Dislike             0      338       0         0
  Ingratitude         0        2       0         0
  Shame               0       82       0         0
  Compassion          0       29       0         0
  Humility            0       19       0         0
  Despair             0       47       0         0
  Anxiety             0       97       0         0
  Daze                0       14       0         0
  Apathy              0        0      20         0
  Unconcern           0        0      12         0
  Gravity             0        0       0        11
  Surprise            0        0       0         8
  Agitation           0        0       0        27
  Pensiveness         0        0       0        13</code></pre>
<p>Terms can appear in multiple categories, or with multiple parts of speech.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># some duplicate terms</span>
<span class="kw">subset</span>(affect_wordnet, term <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"caring"</span>, <span class="st">"chill"</span>, <span class="st">"hopeful"</span>))</code></pre></div>
<pre><code>     term    pos  category    emotion  
209  caring  NOUN Love        Positive 
248  caring  ADJ  Affection   Positive 
309  caring  ADJ  Liking      Positive 
462  chill   VERB Calmness    Positive 
520  chill   NOUN Fear        Positive 
526  hopeful ADJ  Hope        Positive 
626  chill   NOUN Fear        Negative 
628  chill   VERB Fear        Negative 
1337 caring  ADJ  Compassion  Negative 
1624 hopeful ADJ  Expectation Ambiguous</code></pre>
<p>The term “chill”, for example, is listed as denoting both positive calmness and negative fear, among other emotional affects.</p>
</div>
<div id="application-emotion-in-the-wizard-of-oz" class="section level2">
<h2 class="hasAnchor">
<a href="#application-emotion-in-the-wizard-of-oz" class="anchor"></a>Application: Emotion in <em>The Wizard of Oz</em>
</h2>
<div id="overview-1" class="section level3">
<h3 class="hasAnchor">
<a href="#overview-1" class="anchor"></a>Overview</h3>
<p>For our final application, we will track emotion word usage over the course of <em>The Wizard of Oz</em>. We will do this by segmenting the novel into small chunks, and then measure the occurrence rates of emotion words in these chunks.</p>
</div>
<div id="lexicon" class="section level3">
<h3 class="hasAnchor">
<a href="#lexicon" class="anchor"></a>Lexicon</h3>
<p>We will first need a lexicon of emotion words. We will take as a starting point the WordNet-Affect lexicon, but we will remove “Neutral” emotion words.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">affect &lt;-<span class="st"> </span><span class="kw">subset</span>(affect_wordnet, emotion <span class="op">!=</span><span class="st"> "Neutral"</span>)
affect<span class="op">$</span>emotion &lt;-<span class="st"> </span><span class="kw">droplevels</span>(affect<span class="op">$</span>emotion) <span class="co"># drop the unused "Neutral" level</span>
affect<span class="op">$</span>category &lt;-<span class="st"> </span><span class="kw">droplevels</span>(affect<span class="op">$</span>category) <span class="co"># drop unused categories</span></code></pre></div>
<p>Rather than blindly applying the lexicon, we first check to see what the most common emotion terms are.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data, <span class="dt">subset =</span> term <span class="op">%in%</span><span class="st"> </span>affect<span class="op">$</span>term)</code></pre></div>
<pre><code>   term       count support
1  down          93      22
2  great        138      20
3  good          74      20
4  like          64      19
5  heart         67      16
6  yellow        33      14
7  near          20      14
8  glad          19      14
9  afraid        29      13
10 still         20      12
11 surprise      15      12
12 happy         15      11
13 wicked        72      10
14 low           15      10
15 close         13      10
16 terrible      27       9
17 sorry         14       9
18 frightened    13       9
19 blue          21       8
20 dark          16       8
⋮  (168 rows total)</code></pre>
<p>A few terms jump out as unusual: “yellow” is probably for the yellow brick road; “down” and “near” probably do not evoke emotions. We can inspect the usages of the most common terms using the <code>text_locate</code> function, which shows these terms in context.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_sample</a></span>(data, <span class="st">"down"</span>)</code></pre></div>
<pre><code>   text                  before                   instance                   after                  
1  ch12 … Toto and\nthe Lion were tired, and lay    down    upon the grass and fell asleep, with\nt…
2  ch11 …ssed the night moving his joints up and    down   \nto make sure they kept in good working…
3  ch08 …s grew heavy\nand she felt she must sit    down    to rest and to sleep.\n\nBut the Tin Wo…
4  ch22 …struck by a cannon ball.\n\nDorothy ran    down    and helped the Scarecrow to his feet, a…
5  ch04 …ly stuffed with straw.'\nThen he hopped    down    at my feet and ate all the corn he want…
6  ch19 …ame\nunder the first branches they bent    down    and twined around him, and the\nnext mi…
7  ch02 …e saw.\n\nThe cyclone had set the house    down    very gently--for a cyclone--in the\nmid…
8  ch22 …ades safely\nover the hill and set them    down    in the beautiful country of the\nQuadli…
9  ch03 …er in a friendly way.  Then she climbed    down    from the fence\nand walked up to it, wh…
10 ch04 …f dried leaves in one\ncorner.  She lay    down    at once, and with Toto beside her soon …
11 ch17 …Room he greeted her pleasantly:\n\n"Sit    down   , my dear; I think I have found the way …
12 ch14 …e could\ndo.  At his word the band flew    down    and seized Quelala, carried him in\nthe…
13 ch07 …er Dorothy with dry leaves when she lay    down    to sleep.\nThese kept her very snug and…
14 ch10 …so surprised at this answer that he sat    down    to think it\nover.\n\n"It has been many…
15 ch02 …u shall have them to wear." She reached    down    and picked up\nthe shoes, and after sha…
16 ch07 …ould not leap across it.\n\nSo they sat    down    to consider what they should do, and af…
17 ch20 …ich he found in the\nforest Dorothy lay    down    and slept, for she was tired by the lon…
18 ch12 …She thanked him for saving them and sat    down   \nto breakfast, after which they started…
19 ch12 …back to their work, after which she sat    down    to\nthink what she should do next.  She…
20 ch07 …that is certain.  Neither can\nwe climb    down    into this great ditch.  Therefore, if w…
⋮  (93 rows total)</code></pre>
<p>Here, we use the <code><a href="../reference/text_locate.html">text_sample()</a></code> instead of <code><a href="../reference/text_locate.html">text_locate()</a></code> to return the matches in random order. Since we are only looking at a subset of the matches, we use this option to ensure that we don’t make conclusions about these words using a biased sample. Using <code><a href="../reference/text_locate.html">text_locate()</a></code>, we would would only see the matches at the beginning of the novel.</p>
<p>It looks like “down” is mostly used as a preposition, not an emotion. We will exclude it form the lexicon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_sample</a></span>(data, <span class="st">"good"</span>)</code></pre></div>
<pre><code>   text                  before                   instance                   after                  
1  ch11 …tinued the voice.\n\n"That is where the    Good    Witch of the North kissed me when she b…
2  ch15 …the Witches of the North and South were    good   , and I knew\nthey would do me no harm; …
3  ch10 …e of\neverything, and was glad to get a    good    supper again.\n\nThe woman now gave Dor…
4  ch11 … up and down\nto make sure they kept in    good    working order.  The Lion would have\npr…
5  ch04 …ad\nbrains in your head you would be as    good    a man as any of them, and a\nbetter man…
6  ch15 …\n\n"Just to amuse myself, and keep the    good    people busy, I ordered them to\nbuild t…
7  ch05 … they were quite free from rust\nand as    good    as new.\n\nThe Tin Woodman gave a sigh …
8  ch22 …he leader to Dorothy;\n"so good-bye and    good    luck to you."\n\n"Good-bye, and thank y…
9  ch19 …He knew how to give me brains, and very    good    brains, too," said the\nScarecrow.\n\n"…
10 ch21 …me, O King of Beasts!  You have come in    good    time to fight our\nenemy and bring peac…
11 ch15 …n jewels and precious metals, and every    good    thing\nthat is needed to make one happy…
12 ch10 …nt.  And we have been told that Oz is a    good   \nWizard."\n\n"So he is," said the green…
13 ch23 …rom her\nloving comrades.\n\nGlinda the    Good    stepped down from her ruby throne to gi…
14 ch02 …answered the little woman.  "But I am a    good    witch, and\nthe people love me.  I am n…
15 ch18 …her until she starts back to Kansas for    good    and all."\n\n"Thank you," said Dorothy …
16 ch19 …our lovely City, and everyone has\nbeen    good    to me.  I cannot tell you how grateful …
17 ch07 …dreamed of the Emerald City, and of the    good   \nWizard Oz, who would soon send her bac…
18 ch14 …ollowed by all his band.\n\n"That was a    good    ride," said the little girl.\n\n"Yes, a…
19 ch15 …as Dorothy," said the Lion gravely.\n\n"   Good    gracious!" exclaimed the man, and he bo…
20 ch14 … was never known to hurt anyone who was    good   .  Her name\nwas Gayelette, and she live…
⋮  (74 rows total)</code></pre>
<p>“Good” seems to be an appropriate emotion work, evoking positive affection or love. We will keep it in the lexicon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_sample</a></span>(data, <span class="st">"heart"</span>)</code></pre></div>
<pre><code>   text                  before                   instance                   after                  
1  ch15 …crow.\n\n"And you promised to give me a   heart   ," said the Tin Woodman.\n\n"And you pro…
2  ch09 …you," replied the Woodman.  "I have no\n  heart   , you know, so I am careful to help all …
3  ch18 …ourn for the man who gave\nme my lovely   heart   .  I should like to cry a little because…
4  ch14 … anywhere at all."\n\nThen Dorothy lost   heart   .  She sat down on the grass and looked …
5  ch07 …eatures\nfrightened me so badly that my   heart    is beating yet."\n\n"Ah," said the Tin …
6  ch05 …rth; but no one\ncan love who has not a   heart   , and so I am resolved to ask Oz to give…
7  ch06 …appy.\nBut whenever there is danger, my   heart    begins to beat fast."\n\n"Perhaps you h…
8  ch15 …hout a murmur, if you will\ngive me the   heart   ."\n\n"Very well," answered Oz meekly.  …
9  ch19 …" said the Tin Woodman, as he\nfelt his   heart    rattling around in his breast.\n\n"He k…
10 ch08 … like them better."\n\n"If I only had a   heart   , I should love them," added the Tin Woo…
11 ch11 …said, gruffly: "If you indeed desire a\n  heart   , you must earn it."\n\n"How?" asked the…
12 ch11 …u, I am such a fool."\n\n"I haven't the   heart    to harm even a Witch," remarked the Tin…
13 ch05 …new why he was so anxious to get a\nnew   heart   .\n\n"All the same," said the Scarecrow,…
14 ch18 …n Woodman, "am well-pleased with my new   heart   ;\nand, really, that was the only thing …
15 ch15 …knew it, you are in\nluck not to have a   heart   ."\n\n"That must be a matter of opinion,…
16 ch23 …oving\nlittle girl.\n\n"Bless your dear   heart   ," she said, "I am sure I can tell you o…
17 ch16  …\n"Oh, very!" answered Oz.  He put the   heart    in the Woodman's breast and\nthen repla…
18 ch05 …, "I shall ask for brains instead of\na   heart   ; for a fool would not know what to do w…
19 ch01 …uld scream\nand press her hand upon her   heart    whenever Dorothy's merry voice\nreached…
20 ch16 …hole\nin your breast, so I can put your   heart    in the right place.  I hope it\nwon't h…
⋮  (67 rows total)</code></pre>
<p>“Heart” is mostly used as an object (noun), not an emotion meaning compassion. The Tin Woodman’s search for a heart is a central plot of the novel, so it is not surprising that the term shows up frequently. We can look for co-occurrences of “heart” with “woodman”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="st">"heart"</span>)
before &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_locate.html">text_detect</a></span>(<span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(loc<span class="op">$</span>before, <span class="op">-</span><span class="dv">25</span>, <span class="op">-</span><span class="dv">1</span>), <span class="st">"woodman"</span>)
after &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_locate.html">text_detect</a></span>(<span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(loc<span class="op">$</span>after, <span class="dv">1</span>, <span class="dv">25</span>), <span class="st">"woodman"</span>)
<span class="kw">summary</span>(before <span class="op">|</span><span class="st"> </span>after)</code></pre></div>
<pre><code>   Mode   FALSE    TRUE 
logical      22      45 </code></pre>
<p>“Woodman” appears within 25 tokens of “heart” in in 45 of the 67 contexts where the latter word appears.</p>
<p>The decision of whether to include or exclude “heart” is a difficult judgment call. Most of the time it appears, it describes an object, not an emotion. Still, that object does have an emotional association. I’m deciding to include “heart”, but this is not a clear-cut decision.</p>
<p>We can also inspect the first token after each appearance of “yellow”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(<span class="kw"><a href="../reference/text_sub.html">text_sub</a></span>(<span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="st">"yellow"</span>)<span class="op">$</span>after, <span class="dv">1</span>, <span class="dv">1</span>))</code></pre></div>
<pre><code>   term     count support
1  brick       16      16
2  and          3       3
3  winkies      3       3
4  bricks       2       2
5  castle       2       2
6  daisies      1       1
7  flowers      1       1
8  in           1       1
9  land         1       1
10 road-bed     1       1
11 rooms        1       1
12 wildcat      1       1</code></pre>
<p>Over half the time, “yellow” prefaces “brick” or “bricks”, and otherwise it describes objects. It does not describe or evoke emotion, and we should exclude it from the lexicon.</p>
<p>Similar analysis not shown here indicates that “great” is mostly used to describe size, not positive enthusiasm; “like” is often used to mean “similar to”, not “affection for”; “blue” is mostly used as a color, not an emotion.</p>
<p>All of this analysis shows that we should probably exclude some of the common terms from the lexicon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">affect &lt;-<span class="st"> </span><span class="kw">subset</span>(affect, <span class="op">!</span>term <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"down"</span>, <span class="st">"great"</span>, <span class="st">"like"</span>, <span class="st">"yellow"</span>, <span class="st">"near"</span>, <span class="st">"low"</span>, <span class="st">"blue"</span>))</code></pre></div>
</div>
<div id="term-emotion-matrix" class="section level3">
<h3 class="hasAnchor">
<a href="#term-emotion-matrix" class="anchor"></a>Term emotion matrix</h3>
<p>Now that we have a lexicon, our plan is to segment the text into smaller chunks and then compute the emotion occurrence rates in each chunk, broken down by category (“Positive”, “Negative”, or “Ambiguous”).</p>
<p>To facilitate the rate computations, we will form a term-by-emotion rate for the lexicon:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">term_scores &lt;-<span class="st"> </span><span class="kw">with</span>(affect, <span class="kw">unclass</span>(<span class="kw">table</span>(term, emotion)))
<span class="kw">head</span>(term_scores)</code></pre></div>
<pre><code>            emotion
term         Positive Negative Ambiguous
  abase             0        2         0
  abash             0        1         0
  abashed           0        1         0
  abashment         0        1         0
  abhor             0        1         0
  abhorrence        0        1         0</code></pre>
<p>Here, <code>term_scores</code> is a matrix with entry <em>(i,j)</em> indicating the number of times that term <em>i</em> appeared in the affect lexicon with emotion <em>j</em>.</p>
<p>We re-classify any term appearing in two or more categories as ambiguous:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ncat &lt;-<span class="st"> </span><span class="kw">rowSums</span>(term_scores <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)
term_scores[ncat <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>, <span class="kw">c</span>(<span class="st">"Positive"</span>, <span class="st">"Negative"</span>, <span class="st">"Ambiguous"</span>)] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</code></pre></div>
<p>At this point, every term is in one category, but the score for the term could be 2, 3, or more, depending on the number of sub-categories the term appeared in. We replace these larger values with one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">term_scores[term_scores <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">1</span></code></pre></div>
</div>
<div id="segmenting-chapters-into-smaller-chunks" class="section level3">
<h3 class="hasAnchor">
<a href="#segmenting-chapters-into-smaller-chunks" class="anchor"></a>Segmenting chapters into smaller chunks</h3>
<p>To compute emotion occurrence rates, we start by splitting each chapter into equal-sized segments of at most 500 tokens. The specific size of 500 tokens is somewhat arbitrary, but not entirely so. We want the segments to be large enough so that our rate estimates are reliable, but not so large that the emotion usage is heterogeneous within the segment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chunks &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_split.html">text_split</a></span>(data, <span class="st">"tokens"</span>, <span class="dv">500</span>)</code></pre></div>
<p>Within a chapter, the segments all have approximately the same size. However, since the chapters have different lengths, there is some variation in segment size across chapters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(n &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_tokens.html">text_ntoken</a></span>(chunks))</code></pre></div>
<pre><code> [1] 381 381 380 401 400 400 400 400 489 489 489 488 478 478 478 411 411 411 411 410 500 499 499 450
[25] 450 449 449 482 482 481 481 461 461 461 488 488 487 487 451 451 451 451 451 451 451 451 459 459
[49] 459 458 458 458 458 458 396 396 396 472 471 471 471 460 460 460 460 460 460 461 460 384 384 383
[73] 388 387 387 337 337 337 500 500 500 446 445 466 465 417 417 416  74</code></pre>
<p>(If we wanted equal sized segments, we could have concatenated the chapters together and then split the combined text. The disadvantage of this approach is that some segments would be split across multiple chapters.)</p>
</div>
<div id="computing-emotion-rates" class="section level3">
<h3 class="hasAnchor">
<a href="#computing-emotion-rates" class="anchor"></a>Computing emotion rates</h3>
<p>For the count of each emotion category in each segment, we form a text-by-term matrix of counts, and then multiply this by the term-by-emotion score matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_matrix.html">term_matrix</a></span>(chunks, <span class="dt">select =</span> <span class="kw">rownames</span>(term_scores))
text_scores &lt;-<span class="st"> </span>x <span class="op">%*%</span><span class="st"> </span>term_scores</code></pre></div>
<p>For the occurrence rates, we divide the counts by the segment sizes. We then multiply by 1000 so that rates are given as occurrences per 1000 tokens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the rates per 1000 tokens</span>
unit &lt;-<span class="st"> </span><span class="dv">1000</span>
rate &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">pos =</span> text_scores[, <span class="st">"Positive"</span>] <span class="op">/</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span>unit,
             <span class="dt">neg =</span> text_scores[, <span class="st">"Negative"</span>] <span class="op">/</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span>unit,
             <span class="dt">ambig =</span> text_scores[, <span class="st">"Ambiguous"</span>] <span class="op">/</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span>unit)
rate<span class="op">$</span>total &lt;-<span class="st"> </span>rate<span class="op">$</span>pos <span class="op">+</span><span class="st"> </span>rate<span class="op">$</span>neg <span class="op">+</span><span class="st"> </span>rate<span class="op">$</span>ambig</code></pre></div>
<p>We use the binomial variance formula to get the standard errors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the standard errors</span>
se &lt;-<span class="st"> </span><span class="kw">lapply</span>(rate, <span class="cf">function</span>(r) <span class="kw">sqrt</span>(r <span class="op">*</span><span class="st"> </span>(unit <span class="op">-</span><span class="st"> </span>r) <span class="op">/</span><span class="st"> </span>n))</code></pre></div>
<p>This is a crude estimate that makes some independence assumptions, but it gives a reasonable approximation of the uncertainty associated with our measured rates.</p>
</div>
<div id="plotting-the-results" class="section level3">
<h3 class="hasAnchor">
<a href="#plotting-the-results" class="anchor"></a>Plotting the results</h3>
<p>We plot the four rate curves as time series. Our main focus is on the total emotion usage. For this curve, we also put a horizontal dashed line at its mean, and we indicating the “interesting” segments, those that appear more than two standard deviations away from the main, by putting error bars on these points.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up segment IDs</span>
i &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw">nrow</span>(chunks))

<span class="co"># set the plot margins, with extra space below the plot</span>
<span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">11</span>, <span class="dv">9</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>, <span class="dt">las =</span> <span class="dv">1</span>)

<span class="co"># set up the plot coordinates; put labels but no axes</span>
xlim &lt;-<span class="st"> </span><span class="kw">range</span>(i <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>, i <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span>)
ylim &lt;-<span class="st"> </span><span class="kw">range</span>(<span class="dv">0</span>, rate<span class="op">$</span>total <span class="op">+</span><span class="st"> </span>se<span class="op">$</span>total, rate<span class="op">$</span>total <span class="op">-</span><span class="st"> </span>se<span class="op">$</span>total)
<span class="kw">plot</span>(xlim, ylim, <span class="dt">type =</span> <span class="st">"n"</span>, <span class="dt">xlab =</span> <span class="st">"Segment"</span>, <span class="dt">ylab =</span> <span class="st">"Rate \u00d7 1000"</span>, <span class="dt">axes =</span> <span class="ot">FALSE</span>,
     <span class="dt">xaxs =</span> <span class="st">"i"</span>)
usr &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="st">"usr"</span>) <span class="co"># get the user coordinates for later</span>

<span class="co"># put tick marks at multiples of 5 on the x axis; labels at multiples of 10</span>
<span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">at =</span> i[i <span class="op">%%</span><span class="st"> </span><span class="dv">5</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>], <span class="dt">labels =</span> <span class="ot">FALSE</span>)
<span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">at =</span> i[i <span class="op">%%</span><span class="st"> </span><span class="dv">10</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>], <span class="dt">labels =</span> <span class="ot">TRUE</span>)

<span class="co"># defaults for the y axis</span>
<span class="kw">axis</span>(<span class="dv">2</span>)

<span class="co"># put vertical lines at chapter boundaries</span>
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">tapply</span>(i, chunks<span class="op">$</span>parent, min) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dt">col =</span> <span class="st">"gray"</span>)

<span class="co"># put chapter titles above the plot</span>
labels &lt;-<span class="st"> </span>data<span class="op">$</span>title
at &lt;-<span class="st"> </span><span class="kw">tapply</span>(i, chunks<span class="op">$</span>parent, mean)

<span class="co"># (adapted from https://www.r-bloggers.com/rotated-axis-labels-in-r-plots/)</span>
<span class="kw">text</span>(at, usr[<span class="dv">4</span>] <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span> <span class="op">*</span><span class="st"> </span><span class="kw">diff</span>(usr[<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>]),
     <span class="dt">labels =</span> labels, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">srt =</span> <span class="dv">45</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">xpd =</span> <span class="ot">TRUE</span>)

<span class="co"># frame the plot</span>
<span class="kw">box</span>()

<span class="co"># colors for the different emotions, from RColorBrewer::brewer.pal(3, "Set2")</span>
col &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">total =</span> <span class="st">"#000000"</span>, <span class="dt">pos =</span> <span class="st">"#FC8D62"</span>, <span class="dt">neg =</span> <span class="st">"#8DA0CB"</span>, <span class="dt">ambig =</span> <span class="st">"#66C2A5"</span>)

<span class="co"># add a legend on the right hand side</span>
<span class="kw">legend</span>(usr[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="fl">0.015</span> <span class="op">*</span><span class="st"> </span><span class="kw">diff</span>(usr[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]), usr[<span class="dv">3</span>] <span class="op">+</span><span class="st"> </span><span class="fl">0.8</span> <span class="op">*</span><span class="st"> </span><span class="kw">diff</span>(usr[<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>]),
       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">"Total"</span>, <span class="st">"Positive"</span>, <span class="st">"Negative"</span>, <span class="st">"Ambiguous"</span>),
       <span class="dt">title =</span> <span class="kw">expression</span>(<span class="kw">bold</span>(<span class="st">"Emotion"</span>)),
       <span class="dt">fill =</span> col[<span class="kw">c</span>(<span class="st">"total"</span>, <span class="st">"pos"</span>, <span class="st">"neg"</span>, <span class="st">"ambig"</span>)],
       <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">xpd =</span> <span class="ot">TRUE</span>)

<span class="co"># for the total rate, put a dashed line at the mean rate</span>
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="kw">mean</span>(rate<span class="op">$</span>total), <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> col[[<span class="st">"total"</span>]])

<span class="co"># plot each rate type</span>
<span class="cf">for</span> (t <span class="cf">in</span> <span class="kw">c</span>(<span class="st">"ambig"</span>, <span class="st">"neg"</span>, <span class="st">"pos"</span>, <span class="st">"total"</span>)) {
    r &lt;-<span class="st"> </span>rate[[t]]
    s &lt;-<span class="st"> </span>se[[t]]
    cl &lt;-<span class="st"> </span>col[[t]]

    <span class="co"># add lines and points</span>
    <span class="kw">lines</span>(i, r, <span class="dt">col =</span> cl)
    <span class="kw">points</span>(i, r, <span class="dt">col =</span> cl, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">cex =</span> <span class="fl">0.5</span>)

    <span class="co"># for the total, put standard errors around interesting points</span>
    <span class="cf">if</span> (t <span class="op">==</span><span class="st"> "total"</span>) {
        <span class="co"># "interesting" defined as rate &gt;2 sd away from mean</span>
        int &lt;-<span class="st"> </span><span class="kw">abs</span>((r <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(r)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(r)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span>

        <span class="kw">segments</span>(i[int], (r <span class="op">-</span><span class="st"> </span>s)[int], i[int], (r <span class="op">+</span><span class="st"> </span>s)[int], <span class="dt">col =</span> cl)
        <span class="kw">segments</span>((i <span class="op">-</span><span class="st"> </span>.<span class="dv">2</span>)[int], (r <span class="op">-</span><span class="st"> </span>s)[int], (i <span class="op">+</span><span class="st"> </span>.<span class="dv">2</span>)[int], (r <span class="op">-</span><span class="st"> </span>s)[int], <span class="dt">col =</span> cl)
        <span class="kw">segments</span>((i <span class="op">-</span><span class="st"> </span>.<span class="dv">2</span>)[int], (r <span class="op">+</span><span class="st"> </span>s)[int], (i <span class="op">+</span><span class="st"> </span>.<span class="dv">2</span>)[int], (r <span class="op">+</span><span class="st"> </span>s)[int], <span class="dt">col =</span> cl)
    }
}</code></pre></div>
<div class="figure">
<img src="corpus-emotion-1.png" alt="Emotion in Oz"><p class="caption">Emotion in Oz</p>
</div>
</div>
<div id="discussion" class="section level3">
<h3 class="hasAnchor">
<a href="#discussion" class="anchor"></a>Discussion</h3>
<p>This is a crude measurement, but it appears to give a reasonable approximation of the emotional dynamics of the novel. There are some interesting dynamics to the “Positive” and “Negative” emotions, but I’m going to focus on the “Total” emotion.</p>
<p>There are five segments where the rate of emotion word usage is two or more standard deviations above the mean for the rest of the novel. In all five cases, these are statistically significant differences (more than two standard errors above the mean). The first two interesting segments are when Dorothy meets the Tin Woodman and the Cowardly Lion. The next is when the Dorothy and her companions meet the Great Oz for the first time and he tasks them with defeating the Wicked Witch of the West; this is the point in the novel with the highest emotion word usage. The fourth interesting point is when Oz is revealed to be a common man, not a great wizard. The last emotional segment is when Dorothy and her companions leave the Emerald city feeling triumphant and hopeful.</p>
</div>
</div>
<div id="summary" class="section level2">
<h2 class="hasAnchor">
<a href="#summary" class="anchor"></a>Summary</h2>
<p>The <em>corpus</em> library provides facilities for transforming texts into sequences of tokens and for computing the statistics of these sequences. The <code><a href="../reference/text_filter.html">text_filter()</a></code> function allows us to control the transformation from text to tokens. The <code><a href="../reference/text_stats.html">text_stats()</a></code> and <code><a href="../reference/term_stats.html">term_stats()</a></code> functions compute text- and term-level occurrence statistics. The <code><a href="../reference/text_locate.html">text_locate()</a></code> function and allow us to search for terms within texts. The <code><a href="../reference/term_matrix.html">term_matrix()</a></code> function computes a text-by-term frequency matrix. These functions and their variants provide the building blocks for analyzing text.</p>
<p>For more information, check the other vignettes or the package documentation with <code>library(help = "corpus")</code>.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#overview">Overview</a></li>
      <li><a href="#setup">Setup</a></li>
      <li><a href="#data-preparation">Data preparation</a></li>
      <li><a href="#corpus-object">Corpus object</a></li>
      <li><a href="#tokenization">Tokenization</a></li>
      <li><a href="#texts-as-sequences">Texts as sequences</a></li>
      <li><a href="#text-statistics">Text statistics</a></li>
      <li><a href="#term-statistics">Term statistics</a></li>
      <li><a href="#searching-for-terms">Searching for terms</a></li>
      <li><a href="#segmenting-text">Segmenting text</a></li>
      <li><a href="#term-frequency-matrix">Term frequency matrix</a></li>
      <li><a href="#emotion-lexicon">Emotion lexicon</a></li>
      <li><a href="#application-emotion-in-the-wizard-of-oz">Application: Emotion in <em>The Wizard of Oz</em></a></li>
      <li><a href="#summary">Summary</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Patrick O. Perry.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
